{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enriquegiottonini/TAIA-2024/blob/main/1_RNN_LSTM_Vanilla.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sk2aURPyn7mB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from time import perf_counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrFS7EOpn7mD"
      },
      "source": [
        "Vamos entonces a desarrollar la función de alimentación a adelante de una RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIc_g7nVn7mF"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZtzcbOdn7mL"
      },
      "outputs": [],
      "source": [
        "def forward_V_RNN(inputs, weights):\n",
        "    # Forward propagation para una RNN vanilla\n",
        "    x_t, h_t_prev = inputs\n",
        "    w_hh, w_xh, b_h = weights\n",
        "    z_t = w_hh @ h_t_prev + w_xh @ x_t + b_h\n",
        "    h_t = sigmoid(z_t)\n",
        "    return h_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "D7dv3lyYn7mU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58baf45-6d0e-48f5-f738-db05ceb65bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h_t=array([[0.80749125],\n",
            "       [0.00234686]])\n"
          ]
        }
      ],
      "source": [
        "# Data\n",
        "neurons_hidden = 2   # Dimensión del vector de variables ocultas\n",
        "neurons_input = 3   # Dimensión del vector de entrada\n",
        "\n",
        "w_hx = np.random.randn(neurons_hidden, neurons_input)\n",
        "w_hh = np.random.randn(neurons_hidden, neurons_hidden)\n",
        "x_t = np.random.randn(neurons_input,1)\n",
        "b_h = np.random.randn(neurons_hidden, 1)\n",
        "h_t_prev = np.random.randn(neurons_hidden,1)\n",
        "\n",
        "# Aplicando un solo paso\n",
        "h_t = forward_V_RNN([x_t, h_t_prev], [w_hh, w_hx, b_h])\n",
        "\n",
        "print(f\"{h_t=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIcjnlVhn7mc"
      },
      "source": [
        "## RNN tipo LSTM\n",
        "\n",
        "Una LST es un modelo como el que se muestra en la figura, con todo y sus ecuaciones\n",
        "\n",
        "![](https://github.com/mcd-unison/pln/blob/main/labs/RNN/LSTM.jpg?raw=1)\n",
        "\n",
        "Como podemos ver tenemos 3 vectores de entrada a la celda:\n",
        "\n",
        "- $h^{<t-1>}$ el vector de variables ocultas provenientes de un paso anterior,\n",
        "- $C^{<t-1>}$ el vector de valores de celda (memoria de largo plazo) provenientes de un paso anterior,\n",
        "- $x^{<t>}$ el vector de variables de entrada. Idealmente debería estar normalizado entre -1 y 1 cada uno de los valores de entrada.\n",
        "\n",
        "Como podemos ver tenemos varias operaciones:\n",
        "\n",
        "- Una compuerta de olvido $f$ que depende de $h^{<t-1>}$ y $x^{<t>}$ cuya salida es un vector del tamaño de las variables ocultas con valores entre 0 y 1 con la importancia que debe tener el valor de celda anterior (memoria de largo plazo)\n",
        "\n",
        "- Una compuerta de entrada $i$ que depende de $h^{<t-1>}$ y $x^{<t>}$ cuya salida es un vector del tamaño de las variables ocultas con valores entre 0 y 1 con la importancia que debe tener la activación de la celda actual (memoria de corto plazo)\n",
        "\n",
        "- Una compuerta de salida $i$ que depende de $h^{<t-1>}$ y $x^{<t>}$ cuya salida es un vector del tamaño de las variables ocultas con valores entre 0 y 1 con la importancia que debe tener el valor de celda actual en el valor de la de la variable oculta correspondiente.\n",
        "\n",
        "- El calculo de la activación actual, que depende de $h^{<t-1>}$ y $x^{<t>}$, el cual se hace con una tangente hiperbólica, para mantener los valores entre -1 y 1.\n",
        "\n",
        "\n",
        "Hagamos entonces una celda LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOVhoAYhn7mh"
      },
      "outputs": [],
      "source": [
        "def forward_LSTM(inputs, weights):\n",
        "    Xt, ht_prev, Ct_prev = inputs\n",
        "    Ui, Wi, Uf, Wf, Uo, Wo, U, W = weights\n",
        "\n",
        "    i = sigmoid(Xt @ Ui + ht_prev @ Wi) # Compuerta de entrada\n",
        "    f = sigmoid(Xt @ Uf + ht_prev @ Wf) # Compuerta de olvido\n",
        "    o = sigmoid(Xt @ Uo + ht_prev @ Wo) # Compuerta de salida\n",
        "    C_t_short = np.tanh(Xt @ U + ht_prev @ W)  # Memoria de corto plazo\n",
        "    C_t = sigmoid(f * Ct_prev + i * C_t_short) # Memoria de corto y largo plazo\n",
        "\n",
        "    h_t = np.tanh(C_t) * o\n",
        "    return h_t, C_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwtuB538n7mi"
      },
      "source": [
        "Vamos a probar como funciona"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1evrxx5Qn7mo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d7b57ba-8f0c-48e3-d157-53d0e14746ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h_t=array([[0.27287196, 0.00031408],\n",
            "       [0.27284445, 0.00030528]])\n",
            "\n",
            "C_t=array([[0.71848709, 0.38409632],\n",
            "       [0.71838702, 0.37229156]])\n"
          ]
        }
      ],
      "source": [
        "# Data\n",
        "nh = 2   # Dimensión del vector de variables ocultas\n",
        "nx = 3   # Dimensión del vector de entrada\n",
        "neurons_hidden = 2\n",
        "neurons_input = 3\n",
        "\n",
        "Ui = np.random.randn(neurons_input, neurons_hidden)\n",
        "Wi = np.random.randn(neurons_hidden, neurons_hidden)\n",
        "\n",
        "Uf = np.random.randn(neurons_input, neurons_hidden)\n",
        "Wf = np.random.randn(neurons_hidden, neurons_hidden)\n",
        "\n",
        "Uo = np.random.randn(neurons_input, neurons_hidden)\n",
        "Wo = np.random.randn(neurons_hidden, neurons_hidden)\n",
        "\n",
        "U = np.random.randn(neurons_input, neurons_hidden)\n",
        "W = np.random.randn(neurons_hidden, neurons_hidden)\n",
        "\n",
        "h_t_prev = 2 * np.random.standard_normal((1, neurons_hidden)) - 1\n",
        "C_t_prev = np.random.standard_normal((neurons_hidden,1))\n",
        "x_t = 2 * np.random.standard_normal((1,neurons_input)) - 1\n",
        "\n",
        "# Aplicando un solo paso\n",
        "h_t, C_t = forward_LSTM(\n",
        "    [x_t, h_t_prev, C_t_prev],\n",
        "    [Ui, Wi, Uf, Wf, Uo, Wo, U, W]\n",
        ")\n",
        "print(f\"{h_t=}\\n\\n{C_t=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3icIqY81n7mq"
      },
      "source": [
        "## La función `scan`para el cálculo de BPTT\n",
        "\n",
        "La función `scan` se usa para calcular la propagación hacia adelante. Si la funcións e implementa en un *framework* como *Tensorflow* o *pytorch*, entonces se puede ir guardando los gradientes de cada aplicación a lo largo del tiempo y usarlos en el calculo del gradiente para la función de aprendizaje.\n",
        "\n",
        "Aquí solo vamos a tratar de mostrar como funcionaría dicha función, la cual recibe:\n",
        "\n",
        "- `elems` : lista de entradas (`X`)\n",
        "- `weights` : los parámetros que necesita la función de feedforward para su cálculo (pesos)\n",
        "- `h_0` : estado oculto inicial\n",
        "\n",
        "`scan` va por todos los valores de `x` en `elems`, llama la función de feedforward con los argumentos necesarios, guarda el estado oculto `h_t` y agrega el valor de `h_t` a una lista.\n",
        "\n",
        "Vamos a hacer la función de scan para una celda tipo RNN vainilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Y3S6I-Jn7mr"
      },
      "outputs": [],
      "source": [
        "def scan_V_RNN(elems, weights, h_0): # Forward propagation for RNNs\n",
        "    h_t = h_0\n",
        "    h = []\n",
        "    for i, x in enumerate(elems):\n",
        "        h_t = forward_V_RNN([x, h_t], weights)\n",
        "        h.append(h_t)\n",
        "    return h, h_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UarfSCRxn7my"
      },
      "source": [
        "Vamos a probar inicializando una posible red RNN vainilla en un probable pornblema de PLN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCa29yrDn7mz"
      },
      "outputs": [],
      "source": [
        "np.random.seed(10)\n",
        "\n",
        "emb = 128                       # Embedding\n",
        "T = 256                         # Tamaño de secuencia de tokens\n",
        "h_dim = 16                      # Estados ocultos\n",
        "\n",
        "h_0 = np.zeros((h_dim, 1))      # Estado inicial\n",
        "\n",
        "# Inicialización aleatoria de pesos y sesgos\n",
        "Whh = np.random.standard_normal((h_dim, h_dim))\n",
        "Wxh = np.random.standard_normal((h_dim, emb))\n",
        "bh = np.random.standard_normal((h_dim, 1))\n",
        "\n",
        "# Inicialización aleatoria de una secuencia de tokens (en embeddings)\n",
        "X = np.random.standard_normal((T, emb))\n",
        "\n",
        "weights = [Whh, Wxh, bh]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SIaSGYDn7m0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "667bc119-e9b3-4c39-c7c1-ca3608a0743a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tomó 6.88ms ejecutar el método de RNN vainilla.\n"
          ]
        }
      ],
      "source": [
        "# vanilla RNNs\n",
        "tic = perf_counter()\n",
        "h, h_T = scan_V_RNN(X, weights, h_0)\n",
        "toc = perf_counter()\n",
        "RNN_time=(toc-tic)*1000\n",
        "print (f\"Tomó {RNN_time:.2f}ms ejecutar el método de RNN vainilla.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-_QUxaAn7m1"
      },
      "source": [
        "**Desarrolla la función de scan para LSTM y prueba con la\n",
        "\n",
        "---\n",
        "\n",
        "misma secuencia de entradas para una red LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPSYQRCAn7m1"
      },
      "outputs": [],
      "source": [
        "def scan_LSTM(elems, weights, h0, C0):\n",
        "  ht = h0\n",
        "  Ct = C0\n",
        "  h = []\n",
        "  for x in elems:\n",
        "    ht, Ct = forward_LSTM([x, ht, Ct], weights)\n",
        "    h.append(ht)\n",
        "  return h, ht"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBEB05K_n7m2"
      },
      "outputs": [],
      "source": [
        "np.random.seed(10)\n",
        "\n",
        "emb = 128                       # Embedding\n",
        "T = 256                         # Tamaño de secuencia de tokens\n",
        "h_dim = 16                      # Estados ocultos\n",
        "\n",
        "# Inicialización aleatoria de pesos y sesgos\n",
        "h_0 = np.zeros((1, h_dim))      # Estado inicial\n",
        "C_0 = np.zeros((h_dim, 1))\n",
        "Ui = np.random.randn(emb, h_dim)\n",
        "Wi = np.random.randn(h_dim, h_dim)\n",
        "Uf = np.random.randn(emb, h_dim)\n",
        "Wf = np.random.randn(h_dim, h_dim)\n",
        "Uo = np.random.randn(emb, h_dim)\n",
        "Wo = np.random.randn(h_dim, h_dim)\n",
        "U = np.random.randn(emb, h_dim)\n",
        "W = np.random.randn(h_dim, h_dim)\n",
        "\n",
        "# Inicialización aleatoria de una secuencia de tokens (en embeddings)\n",
        "X = np.random.standard_normal((T, emb))\n",
        "\n",
        "weights = [Ui, Wi, Uf, Wf, Uo, Wo, U, W]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEIujJ0Zn7m3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "555eb06f-8072-4e01-eb5a-7f6afaaf01a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tomó 29.52ms ejecutar el método de RNN vainilla.\n"
          ]
        }
      ],
      "source": [
        "tic = perf_counter()\n",
        "h, h_T = scan_LSTM(X, weights, h_0, C_0)\n",
        "toc = perf_counter()\n",
        "LSTM_time=(toc-tic)*1000\n",
        "print (f\"Tomó {LSTM_time:.2f}ms ejecutar el método de RNN vainilla.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}